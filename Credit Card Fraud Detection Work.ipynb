{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essay "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.under_sampling import EditedNearestNeighbours \n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "from imblearn.under_sampling import OneSidedSelection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, recall_score,precision_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1.449044</td>\n",
       "      <td>-1.176339</td>\n",
       "      <td>0.913860</td>\n",
       "      <td>-1.375667</td>\n",
       "      <td>-1.971383</td>\n",
       "      <td>-0.629152</td>\n",
       "      <td>-1.423236</td>\n",
       "      <td>0.048456</td>\n",
       "      <td>-1.720408</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009302</td>\n",
       "      <td>0.313894</td>\n",
       "      <td>0.027740</td>\n",
       "      <td>0.500512</td>\n",
       "      <td>0.251367</td>\n",
       "      <td>-0.129478</td>\n",
       "      <td>0.042850</td>\n",
       "      <td>0.016253</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>0.384978</td>\n",
       "      <td>0.616109</td>\n",
       "      <td>-0.874300</td>\n",
       "      <td>-0.094019</td>\n",
       "      <td>2.924584</td>\n",
       "      <td>3.317027</td>\n",
       "      <td>0.470455</td>\n",
       "      <td>0.538247</td>\n",
       "      <td>-0.558895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049924</td>\n",
       "      <td>0.238422</td>\n",
       "      <td>0.009130</td>\n",
       "      <td>0.996710</td>\n",
       "      <td>-0.767315</td>\n",
       "      <td>-0.492208</td>\n",
       "      <td>0.042472</td>\n",
       "      <td>-0.054337</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>1.249999</td>\n",
       "      <td>-1.221637</td>\n",
       "      <td>0.383930</td>\n",
       "      <td>-1.234899</td>\n",
       "      <td>-1.485419</td>\n",
       "      <td>-0.753230</td>\n",
       "      <td>-0.689405</td>\n",
       "      <td>-0.227487</td>\n",
       "      <td>-2.094011</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.231809</td>\n",
       "      <td>-0.483285</td>\n",
       "      <td>0.084668</td>\n",
       "      <td>0.392831</td>\n",
       "      <td>0.161135</td>\n",
       "      <td>-0.354990</td>\n",
       "      <td>0.026416</td>\n",
       "      <td>0.042422</td>\n",
       "      <td>121.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11</td>\n",
       "      <td>1.069374</td>\n",
       "      <td>0.287722</td>\n",
       "      <td>0.828613</td>\n",
       "      <td>2.712520</td>\n",
       "      <td>-0.178398</td>\n",
       "      <td>0.337544</td>\n",
       "      <td>-0.096717</td>\n",
       "      <td>0.115982</td>\n",
       "      <td>-0.221083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036876</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.071407</td>\n",
       "      <td>0.104744</td>\n",
       "      <td>0.548265</td>\n",
       "      <td>0.104094</td>\n",
       "      <td>0.021491</td>\n",
       "      <td>0.021293</td>\n",
       "      <td>27.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12</td>\n",
       "      <td>-2.791855</td>\n",
       "      <td>-0.327771</td>\n",
       "      <td>1.641750</td>\n",
       "      <td>1.767473</td>\n",
       "      <td>-0.136588</td>\n",
       "      <td>0.807596</td>\n",
       "      <td>-0.422911</td>\n",
       "      <td>-1.907107</td>\n",
       "      <td>0.755713</td>\n",
       "      <td>...</td>\n",
       "      <td>1.151663</td>\n",
       "      <td>0.222182</td>\n",
       "      <td>1.020586</td>\n",
       "      <td>0.028317</td>\n",
       "      <td>-0.232746</td>\n",
       "      <td>-0.235557</td>\n",
       "      <td>-0.164778</td>\n",
       "      <td>-0.030154</td>\n",
       "      <td>58.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12</td>\n",
       "      <td>-0.752417</td>\n",
       "      <td>0.345485</td>\n",
       "      <td>2.057323</td>\n",
       "      <td>-1.468643</td>\n",
       "      <td>-1.158394</td>\n",
       "      <td>-0.077850</td>\n",
       "      <td>-0.608581</td>\n",
       "      <td>0.003603</td>\n",
       "      <td>-0.436167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499625</td>\n",
       "      <td>1.353650</td>\n",
       "      <td>-0.256573</td>\n",
       "      <td>-0.065084</td>\n",
       "      <td>-0.039124</td>\n",
       "      <td>-0.087086</td>\n",
       "      <td>-0.180998</td>\n",
       "      <td>0.129394</td>\n",
       "      <td>15.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12</td>\n",
       "      <td>1.103215</td>\n",
       "      <td>-0.040296</td>\n",
       "      <td>1.267332</td>\n",
       "      <td>1.289091</td>\n",
       "      <td>-0.735997</td>\n",
       "      <td>0.288069</td>\n",
       "      <td>-0.586057</td>\n",
       "      <td>0.189380</td>\n",
       "      <td>0.782333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024612</td>\n",
       "      <td>0.196002</td>\n",
       "      <td>0.013802</td>\n",
       "      <td>0.103758</td>\n",
       "      <td>0.364298</td>\n",
       "      <td>-0.382261</td>\n",
       "      <td>0.092809</td>\n",
       "      <td>0.037051</td>\n",
       "      <td>12.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13</td>\n",
       "      <td>-0.436905</td>\n",
       "      <td>0.918966</td>\n",
       "      <td>0.924591</td>\n",
       "      <td>-0.727219</td>\n",
       "      <td>0.915679</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>0.707642</td>\n",
       "      <td>0.087962</td>\n",
       "      <td>-0.665271</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194796</td>\n",
       "      <td>-0.672638</td>\n",
       "      <td>-0.156858</td>\n",
       "      <td>-0.888386</td>\n",
       "      <td>-0.342413</td>\n",
       "      <td>-0.049027</td>\n",
       "      <td>0.079692</td>\n",
       "      <td>0.131024</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14</td>\n",
       "      <td>-5.401258</td>\n",
       "      <td>-5.450148</td>\n",
       "      <td>1.186305</td>\n",
       "      <td>1.736239</td>\n",
       "      <td>3.049106</td>\n",
       "      <td>-1.763406</td>\n",
       "      <td>-1.559738</td>\n",
       "      <td>0.160842</td>\n",
       "      <td>1.233090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.503600</td>\n",
       "      <td>0.984460</td>\n",
       "      <td>2.458589</td>\n",
       "      <td>0.042119</td>\n",
       "      <td>-0.481631</td>\n",
       "      <td>-0.621272</td>\n",
       "      <td>0.392053</td>\n",
       "      <td>0.949594</td>\n",
       "      <td>46.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15</td>\n",
       "      <td>1.492936</td>\n",
       "      <td>-1.029346</td>\n",
       "      <td>0.454795</td>\n",
       "      <td>-1.438026</td>\n",
       "      <td>-1.555434</td>\n",
       "      <td>-0.720961</td>\n",
       "      <td>-1.080664</td>\n",
       "      <td>-0.053127</td>\n",
       "      <td>-1.978682</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177650</td>\n",
       "      <td>-0.175074</td>\n",
       "      <td>0.040002</td>\n",
       "      <td>0.295814</td>\n",
       "      <td>0.332931</td>\n",
       "      <td>-0.220385</td>\n",
       "      <td>0.022298</td>\n",
       "      <td>0.007602</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>16</td>\n",
       "      <td>0.694885</td>\n",
       "      <td>-1.361819</td>\n",
       "      <td>1.029221</td>\n",
       "      <td>0.834159</td>\n",
       "      <td>-1.191209</td>\n",
       "      <td>1.309109</td>\n",
       "      <td>-0.878586</td>\n",
       "      <td>0.445290</td>\n",
       "      <td>-0.446196</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.295583</td>\n",
       "      <td>-0.571955</td>\n",
       "      <td>-0.050881</td>\n",
       "      <td>-0.304215</td>\n",
       "      <td>0.072001</td>\n",
       "      <td>-0.422234</td>\n",
       "      <td>0.086553</td>\n",
       "      <td>0.063499</td>\n",
       "      <td>231.71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>17</td>\n",
       "      <td>0.962496</td>\n",
       "      <td>0.328461</td>\n",
       "      <td>-0.171479</td>\n",
       "      <td>2.109204</td>\n",
       "      <td>1.129566</td>\n",
       "      <td>1.696038</td>\n",
       "      <td>0.107712</td>\n",
       "      <td>0.521502</td>\n",
       "      <td>-1.191311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143997</td>\n",
       "      <td>0.402492</td>\n",
       "      <td>-0.048508</td>\n",
       "      <td>-1.371866</td>\n",
       "      <td>0.390814</td>\n",
       "      <td>0.199964</td>\n",
       "      <td>0.016371</td>\n",
       "      <td>-0.014605</td>\n",
       "      <td>34.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>18</td>\n",
       "      <td>1.166616</td>\n",
       "      <td>0.502120</td>\n",
       "      <td>-0.067300</td>\n",
       "      <td>2.261569</td>\n",
       "      <td>0.428804</td>\n",
       "      <td>0.089474</td>\n",
       "      <td>0.241147</td>\n",
       "      <td>0.138082</td>\n",
       "      <td>-0.989162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018702</td>\n",
       "      <td>-0.061972</td>\n",
       "      <td>-0.103855</td>\n",
       "      <td>-0.370415</td>\n",
       "      <td>0.603200</td>\n",
       "      <td>0.108556</td>\n",
       "      <td>-0.040521</td>\n",
       "      <td>-0.011418</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>18</td>\n",
       "      <td>0.247491</td>\n",
       "      <td>0.277666</td>\n",
       "      <td>1.185471</td>\n",
       "      <td>-0.092603</td>\n",
       "      <td>-1.314394</td>\n",
       "      <td>-0.150116</td>\n",
       "      <td>-0.946365</td>\n",
       "      <td>-1.617935</td>\n",
       "      <td>1.544071</td>\n",
       "      <td>...</td>\n",
       "      <td>1.650180</td>\n",
       "      <td>0.200454</td>\n",
       "      <td>-0.185353</td>\n",
       "      <td>0.423073</td>\n",
       "      <td>0.820591</td>\n",
       "      <td>-0.227632</td>\n",
       "      <td>0.336634</td>\n",
       "      <td>0.250475</td>\n",
       "      <td>22.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>22</td>\n",
       "      <td>-1.946525</td>\n",
       "      <td>-0.044901</td>\n",
       "      <td>-0.405570</td>\n",
       "      <td>-1.013057</td>\n",
       "      <td>2.941968</td>\n",
       "      <td>2.955053</td>\n",
       "      <td>-0.063063</td>\n",
       "      <td>0.855546</td>\n",
       "      <td>0.049967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.579526</td>\n",
       "      <td>-0.799229</td>\n",
       "      <td>0.870300</td>\n",
       "      <td>0.983421</td>\n",
       "      <td>0.321201</td>\n",
       "      <td>0.149650</td>\n",
       "      <td>0.707519</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>22</td>\n",
       "      <td>-2.074295</td>\n",
       "      <td>-0.121482</td>\n",
       "      <td>1.322021</td>\n",
       "      <td>0.410008</td>\n",
       "      <td>0.295198</td>\n",
       "      <td>-0.959537</td>\n",
       "      <td>0.543985</td>\n",
       "      <td>-0.104627</td>\n",
       "      <td>0.475664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.403639</td>\n",
       "      <td>-0.227404</td>\n",
       "      <td>0.742435</td>\n",
       "      <td>0.398535</td>\n",
       "      <td>0.249212</td>\n",
       "      <td>0.274404</td>\n",
       "      <td>0.359969</td>\n",
       "      <td>0.243232</td>\n",
       "      <td>26.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>23</td>\n",
       "      <td>1.173285</td>\n",
       "      <td>0.353498</td>\n",
       "      <td>0.283905</td>\n",
       "      <td>1.133563</td>\n",
       "      <td>-0.172577</td>\n",
       "      <td>-0.916054</td>\n",
       "      <td>0.369025</td>\n",
       "      <td>-0.327260</td>\n",
       "      <td>-0.246651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067003</td>\n",
       "      <td>0.227812</td>\n",
       "      <td>-0.150487</td>\n",
       "      <td>0.435045</td>\n",
       "      <td>0.724825</td>\n",
       "      <td>-0.337082</td>\n",
       "      <td>0.016368</td>\n",
       "      <td>0.030041</td>\n",
       "      <td>41.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>23</td>\n",
       "      <td>1.322707</td>\n",
       "      <td>-0.174041</td>\n",
       "      <td>0.434555</td>\n",
       "      <td>0.576038</td>\n",
       "      <td>-0.836758</td>\n",
       "      <td>-0.831083</td>\n",
       "      <td>-0.264905</td>\n",
       "      <td>-0.220982</td>\n",
       "      <td>-1.071425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.284376</td>\n",
       "      <td>-0.323357</td>\n",
       "      <td>-0.037710</td>\n",
       "      <td>0.347151</td>\n",
       "      <td>0.559639</td>\n",
       "      <td>-0.280158</td>\n",
       "      <td>0.042335</td>\n",
       "      <td>0.028822</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>23</td>\n",
       "      <td>-0.414289</td>\n",
       "      <td>0.905437</td>\n",
       "      <td>1.727453</td>\n",
       "      <td>1.473471</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>-0.200331</td>\n",
       "      <td>0.740228</td>\n",
       "      <td>-0.029247</td>\n",
       "      <td>-0.593392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077237</td>\n",
       "      <td>0.457331</td>\n",
       "      <td>-0.038500</td>\n",
       "      <td>0.642522</td>\n",
       "      <td>-0.183891</td>\n",
       "      <td>-0.277464</td>\n",
       "      <td>0.182687</td>\n",
       "      <td>0.152665</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>23</td>\n",
       "      <td>1.059387</td>\n",
       "      <td>-0.175319</td>\n",
       "      <td>1.266130</td>\n",
       "      <td>1.186110</td>\n",
       "      <td>-0.786002</td>\n",
       "      <td>0.578435</td>\n",
       "      <td>-0.767084</td>\n",
       "      <td>0.401046</td>\n",
       "      <td>0.699500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013676</td>\n",
       "      <td>0.213734</td>\n",
       "      <td>0.014462</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.294638</td>\n",
       "      <td>-0.395070</td>\n",
       "      <td>0.081461</td>\n",
       "      <td>0.024220</td>\n",
       "      <td>12.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284777</th>\n",
       "      <td>172764</td>\n",
       "      <td>2.079137</td>\n",
       "      <td>-0.028723</td>\n",
       "      <td>-1.343392</td>\n",
       "      <td>0.358000</td>\n",
       "      <td>-0.045791</td>\n",
       "      <td>-1.345452</td>\n",
       "      <td>0.227476</td>\n",
       "      <td>-0.378355</td>\n",
       "      <td>0.665911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235758</td>\n",
       "      <td>0.829758</td>\n",
       "      <td>-0.002063</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.262183</td>\n",
       "      <td>-0.105327</td>\n",
       "      <td>-0.022363</td>\n",
       "      <td>-0.060283</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284778</th>\n",
       "      <td>172764</td>\n",
       "      <td>-0.764523</td>\n",
       "      <td>0.588379</td>\n",
       "      <td>-0.907599</td>\n",
       "      <td>-0.418847</td>\n",
       "      <td>0.901528</td>\n",
       "      <td>-0.760802</td>\n",
       "      <td>0.758545</td>\n",
       "      <td>0.414698</td>\n",
       "      <td>-0.730854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003530</td>\n",
       "      <td>-0.431876</td>\n",
       "      <td>0.141759</td>\n",
       "      <td>0.587119</td>\n",
       "      <td>-0.200998</td>\n",
       "      <td>0.267337</td>\n",
       "      <td>-0.152951</td>\n",
       "      <td>-0.065285</td>\n",
       "      <td>80.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284779</th>\n",
       "      <td>172766</td>\n",
       "      <td>1.975178</td>\n",
       "      <td>-0.616244</td>\n",
       "      <td>-2.628295</td>\n",
       "      <td>-0.406246</td>\n",
       "      <td>2.327804</td>\n",
       "      <td>3.664740</td>\n",
       "      <td>-0.533297</td>\n",
       "      <td>0.842937</td>\n",
       "      <td>1.128798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086043</td>\n",
       "      <td>0.543613</td>\n",
       "      <td>-0.032129</td>\n",
       "      <td>0.768379</td>\n",
       "      <td>0.477688</td>\n",
       "      <td>-0.031833</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>-0.066542</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284780</th>\n",
       "      <td>172766</td>\n",
       "      <td>-1.727503</td>\n",
       "      <td>1.108356</td>\n",
       "      <td>2.219561</td>\n",
       "      <td>1.148583</td>\n",
       "      <td>-0.884199</td>\n",
       "      <td>0.793083</td>\n",
       "      <td>-0.527298</td>\n",
       "      <td>0.866429</td>\n",
       "      <td>0.853819</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094708</td>\n",
       "      <td>0.236818</td>\n",
       "      <td>-0.204280</td>\n",
       "      <td>1.158185</td>\n",
       "      <td>0.627801</td>\n",
       "      <td>-0.399981</td>\n",
       "      <td>0.510818</td>\n",
       "      <td>0.233265</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284781</th>\n",
       "      <td>172766</td>\n",
       "      <td>-1.139015</td>\n",
       "      <td>-0.155510</td>\n",
       "      <td>1.894478</td>\n",
       "      <td>-1.138957</td>\n",
       "      <td>1.451777</td>\n",
       "      <td>0.093598</td>\n",
       "      <td>0.191353</td>\n",
       "      <td>0.092211</td>\n",
       "      <td>-0.062621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191027</td>\n",
       "      <td>-0.631658</td>\n",
       "      <td>-0.147249</td>\n",
       "      <td>0.212931</td>\n",
       "      <td>0.354257</td>\n",
       "      <td>-0.241068</td>\n",
       "      <td>-0.161717</td>\n",
       "      <td>-0.149188</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284782</th>\n",
       "      <td>172767</td>\n",
       "      <td>-0.268061</td>\n",
       "      <td>2.540315</td>\n",
       "      <td>-1.400915</td>\n",
       "      <td>4.846661</td>\n",
       "      <td>0.639105</td>\n",
       "      <td>0.186479</td>\n",
       "      <td>-0.045911</td>\n",
       "      <td>0.936448</td>\n",
       "      <td>-2.419986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263889</td>\n",
       "      <td>-0.857904</td>\n",
       "      <td>0.235172</td>\n",
       "      <td>-0.681794</td>\n",
       "      <td>-0.668894</td>\n",
       "      <td>0.044657</td>\n",
       "      <td>-0.066751</td>\n",
       "      <td>-0.072447</td>\n",
       "      <td>12.82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284783</th>\n",
       "      <td>172768</td>\n",
       "      <td>-1.796092</td>\n",
       "      <td>1.929178</td>\n",
       "      <td>-2.828417</td>\n",
       "      <td>-1.689844</td>\n",
       "      <td>2.199572</td>\n",
       "      <td>3.123732</td>\n",
       "      <td>-0.270714</td>\n",
       "      <td>1.657495</td>\n",
       "      <td>0.465804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271170</td>\n",
       "      <td>1.145750</td>\n",
       "      <td>0.084783</td>\n",
       "      <td>0.721269</td>\n",
       "      <td>-0.529906</td>\n",
       "      <td>-0.240117</td>\n",
       "      <td>0.129126</td>\n",
       "      <td>-0.080620</td>\n",
       "      <td>11.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284784</th>\n",
       "      <td>172768</td>\n",
       "      <td>-0.669662</td>\n",
       "      <td>0.923769</td>\n",
       "      <td>-1.543167</td>\n",
       "      <td>-1.560729</td>\n",
       "      <td>2.833960</td>\n",
       "      <td>3.240843</td>\n",
       "      <td>0.181576</td>\n",
       "      <td>1.282746</td>\n",
       "      <td>-0.893890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183856</td>\n",
       "      <td>0.202670</td>\n",
       "      <td>-0.373023</td>\n",
       "      <td>0.651122</td>\n",
       "      <td>1.073823</td>\n",
       "      <td>0.844590</td>\n",
       "      <td>-0.286676</td>\n",
       "      <td>-0.187719</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284785</th>\n",
       "      <td>172768</td>\n",
       "      <td>0.032887</td>\n",
       "      <td>0.545338</td>\n",
       "      <td>-1.185844</td>\n",
       "      <td>-1.729828</td>\n",
       "      <td>2.932315</td>\n",
       "      <td>3.401529</td>\n",
       "      <td>0.337434</td>\n",
       "      <td>0.925377</td>\n",
       "      <td>-0.165663</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266113</td>\n",
       "      <td>-0.716336</td>\n",
       "      <td>0.108519</td>\n",
       "      <td>0.688519</td>\n",
       "      <td>-0.460220</td>\n",
       "      <td>0.161939</td>\n",
       "      <td>0.265368</td>\n",
       "      <td>0.090245</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284786</th>\n",
       "      <td>172768</td>\n",
       "      <td>-2.076175</td>\n",
       "      <td>2.142238</td>\n",
       "      <td>-2.522704</td>\n",
       "      <td>-1.888063</td>\n",
       "      <td>1.982785</td>\n",
       "      <td>3.732950</td>\n",
       "      <td>-1.217430</td>\n",
       "      <td>-0.536644</td>\n",
       "      <td>0.272867</td>\n",
       "      <td>...</td>\n",
       "      <td>2.016666</td>\n",
       "      <td>-1.588269</td>\n",
       "      <td>0.588482</td>\n",
       "      <td>0.632444</td>\n",
       "      <td>-0.201064</td>\n",
       "      <td>0.199251</td>\n",
       "      <td>0.438657</td>\n",
       "      <td>0.172923</td>\n",
       "      <td>8.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284787</th>\n",
       "      <td>172769</td>\n",
       "      <td>-1.029719</td>\n",
       "      <td>-1.110670</td>\n",
       "      <td>-0.636179</td>\n",
       "      <td>-0.840816</td>\n",
       "      <td>2.424360</td>\n",
       "      <td>-2.956733</td>\n",
       "      <td>0.283610</td>\n",
       "      <td>-0.332656</td>\n",
       "      <td>-0.247488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353722</td>\n",
       "      <td>0.488487</td>\n",
       "      <td>0.293632</td>\n",
       "      <td>0.107812</td>\n",
       "      <td>-0.935586</td>\n",
       "      <td>1.138216</td>\n",
       "      <td>0.025271</td>\n",
       "      <td>0.255347</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284788</th>\n",
       "      <td>172770</td>\n",
       "      <td>2.007418</td>\n",
       "      <td>-0.280235</td>\n",
       "      <td>-0.208113</td>\n",
       "      <td>0.335261</td>\n",
       "      <td>-0.715798</td>\n",
       "      <td>-0.751373</td>\n",
       "      <td>-0.458972</td>\n",
       "      <td>-0.140140</td>\n",
       "      <td>0.959971</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208260</td>\n",
       "      <td>-0.430347</td>\n",
       "      <td>0.416765</td>\n",
       "      <td>0.064819</td>\n",
       "      <td>-0.608337</td>\n",
       "      <td>0.268436</td>\n",
       "      <td>-0.028069</td>\n",
       "      <td>-0.041367</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284789</th>\n",
       "      <td>172770</td>\n",
       "      <td>-0.446951</td>\n",
       "      <td>1.302212</td>\n",
       "      <td>-0.168583</td>\n",
       "      <td>0.981577</td>\n",
       "      <td>0.578957</td>\n",
       "      <td>-0.605641</td>\n",
       "      <td>1.253430</td>\n",
       "      <td>-1.042610</td>\n",
       "      <td>-0.417116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851800</td>\n",
       "      <td>0.305268</td>\n",
       "      <td>-0.148093</td>\n",
       "      <td>-0.038712</td>\n",
       "      <td>0.010209</td>\n",
       "      <td>-0.362666</td>\n",
       "      <td>0.503092</td>\n",
       "      <td>0.229921</td>\n",
       "      <td>60.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284790</th>\n",
       "      <td>172771</td>\n",
       "      <td>-0.515513</td>\n",
       "      <td>0.971950</td>\n",
       "      <td>-1.014580</td>\n",
       "      <td>-0.677037</td>\n",
       "      <td>0.912430</td>\n",
       "      <td>-0.316187</td>\n",
       "      <td>0.396137</td>\n",
       "      <td>0.532364</td>\n",
       "      <td>-0.224606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280302</td>\n",
       "      <td>-0.849919</td>\n",
       "      <td>0.300245</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>-0.376379</td>\n",
       "      <td>0.128660</td>\n",
       "      <td>-0.015205</td>\n",
       "      <td>-0.021486</td>\n",
       "      <td>9.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284791</th>\n",
       "      <td>172774</td>\n",
       "      <td>-0.863506</td>\n",
       "      <td>0.874701</td>\n",
       "      <td>0.420358</td>\n",
       "      <td>-0.530365</td>\n",
       "      <td>0.356561</td>\n",
       "      <td>-1.046238</td>\n",
       "      <td>0.757051</td>\n",
       "      <td>0.230473</td>\n",
       "      <td>-0.506856</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108846</td>\n",
       "      <td>-0.480820</td>\n",
       "      <td>-0.074513</td>\n",
       "      <td>-0.003988</td>\n",
       "      <td>-0.113149</td>\n",
       "      <td>0.280378</td>\n",
       "      <td>-0.077310</td>\n",
       "      <td>0.023079</td>\n",
       "      <td>20.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284792</th>\n",
       "      <td>172774</td>\n",
       "      <td>-0.724123</td>\n",
       "      <td>1.485216</td>\n",
       "      <td>-1.132218</td>\n",
       "      <td>-0.607190</td>\n",
       "      <td>0.709499</td>\n",
       "      <td>-0.482638</td>\n",
       "      <td>0.548393</td>\n",
       "      <td>0.343003</td>\n",
       "      <td>-0.226323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414621</td>\n",
       "      <td>1.307511</td>\n",
       "      <td>-0.059545</td>\n",
       "      <td>0.242669</td>\n",
       "      <td>-0.665424</td>\n",
       "      <td>-0.269869</td>\n",
       "      <td>-0.170579</td>\n",
       "      <td>-0.030692</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284793</th>\n",
       "      <td>172775</td>\n",
       "      <td>1.971002</td>\n",
       "      <td>-0.699067</td>\n",
       "      <td>-1.697541</td>\n",
       "      <td>-0.617643</td>\n",
       "      <td>1.718797</td>\n",
       "      <td>3.911336</td>\n",
       "      <td>-1.259306</td>\n",
       "      <td>1.056209</td>\n",
       "      <td>1.315006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188758</td>\n",
       "      <td>0.694418</td>\n",
       "      <td>0.163002</td>\n",
       "      <td>0.726365</td>\n",
       "      <td>-0.058282</td>\n",
       "      <td>-0.191813</td>\n",
       "      <td>0.061858</td>\n",
       "      <td>-0.043716</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284794</th>\n",
       "      <td>172777</td>\n",
       "      <td>-1.266580</td>\n",
       "      <td>-0.400461</td>\n",
       "      <td>0.956221</td>\n",
       "      <td>-0.723919</td>\n",
       "      <td>1.531993</td>\n",
       "      <td>-1.788600</td>\n",
       "      <td>0.314741</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.013857</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157831</td>\n",
       "      <td>-0.883365</td>\n",
       "      <td>0.088485</td>\n",
       "      <td>-0.076790</td>\n",
       "      <td>-0.095833</td>\n",
       "      <td>0.132720</td>\n",
       "      <td>-0.028468</td>\n",
       "      <td>0.126494</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284795</th>\n",
       "      <td>172778</td>\n",
       "      <td>-12.516732</td>\n",
       "      <td>10.187818</td>\n",
       "      <td>-8.476671</td>\n",
       "      <td>-2.510473</td>\n",
       "      <td>-4.586669</td>\n",
       "      <td>-1.394465</td>\n",
       "      <td>-3.632516</td>\n",
       "      <td>5.498583</td>\n",
       "      <td>4.893089</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.944759</td>\n",
       "      <td>-1.565026</td>\n",
       "      <td>0.890675</td>\n",
       "      <td>-1.253276</td>\n",
       "      <td>1.786717</td>\n",
       "      <td>0.320763</td>\n",
       "      <td>2.090712</td>\n",
       "      <td>1.232864</td>\n",
       "      <td>9.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284796</th>\n",
       "      <td>172780</td>\n",
       "      <td>1.884849</td>\n",
       "      <td>-0.143540</td>\n",
       "      <td>-0.999943</td>\n",
       "      <td>1.506772</td>\n",
       "      <td>-0.035300</td>\n",
       "      <td>-0.613638</td>\n",
       "      <td>0.190241</td>\n",
       "      <td>-0.249058</td>\n",
       "      <td>0.666458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144008</td>\n",
       "      <td>0.634646</td>\n",
       "      <td>-0.042114</td>\n",
       "      <td>-0.053206</td>\n",
       "      <td>0.316403</td>\n",
       "      <td>-0.461441</td>\n",
       "      <td>0.018265</td>\n",
       "      <td>-0.041068</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284797</th>\n",
       "      <td>172782</td>\n",
       "      <td>-0.241923</td>\n",
       "      <td>0.712247</td>\n",
       "      <td>0.399806</td>\n",
       "      <td>-0.463406</td>\n",
       "      <td>0.244531</td>\n",
       "      <td>-1.343668</td>\n",
       "      <td>0.929369</td>\n",
       "      <td>-0.206210</td>\n",
       "      <td>0.106234</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228876</td>\n",
       "      <td>-0.514376</td>\n",
       "      <td>0.279598</td>\n",
       "      <td>0.371441</td>\n",
       "      <td>-0.559238</td>\n",
       "      <td>0.113144</td>\n",
       "      <td>0.131507</td>\n",
       "      <td>0.081265</td>\n",
       "      <td>5.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284798</th>\n",
       "      <td>172782</td>\n",
       "      <td>0.219529</td>\n",
       "      <td>0.881246</td>\n",
       "      <td>-0.635891</td>\n",
       "      <td>0.960928</td>\n",
       "      <td>-0.152971</td>\n",
       "      <td>-1.014307</td>\n",
       "      <td>0.427126</td>\n",
       "      <td>0.121340</td>\n",
       "      <td>-0.285670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099936</td>\n",
       "      <td>0.337120</td>\n",
       "      <td>0.251791</td>\n",
       "      <td>0.057688</td>\n",
       "      <td>-1.508368</td>\n",
       "      <td>0.144023</td>\n",
       "      <td>0.181205</td>\n",
       "      <td>0.215243</td>\n",
       "      <td>24.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284799</th>\n",
       "      <td>172783</td>\n",
       "      <td>-1.775135</td>\n",
       "      <td>-0.004235</td>\n",
       "      <td>1.189786</td>\n",
       "      <td>0.331096</td>\n",
       "      <td>1.196063</td>\n",
       "      <td>5.519980</td>\n",
       "      <td>-1.518185</td>\n",
       "      <td>2.080825</td>\n",
       "      <td>1.159498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103302</td>\n",
       "      <td>0.654850</td>\n",
       "      <td>-0.348929</td>\n",
       "      <td>0.745323</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>-0.127579</td>\n",
       "      <td>0.454379</td>\n",
       "      <td>0.130308</td>\n",
       "      <td>79.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284800</th>\n",
       "      <td>172784</td>\n",
       "      <td>2.039560</td>\n",
       "      <td>-0.175233</td>\n",
       "      <td>-1.196825</td>\n",
       "      <td>0.234580</td>\n",
       "      <td>-0.008713</td>\n",
       "      <td>-0.726571</td>\n",
       "      <td>0.017050</td>\n",
       "      <td>-0.118228</td>\n",
       "      <td>0.435402</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.268048</td>\n",
       "      <td>-0.717211</td>\n",
       "      <td>0.297930</td>\n",
       "      <td>-0.359769</td>\n",
       "      <td>-0.315610</td>\n",
       "      <td>0.201114</td>\n",
       "      <td>-0.080826</td>\n",
       "      <td>-0.075071</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284801</th>\n",
       "      <td>172785</td>\n",
       "      <td>0.120316</td>\n",
       "      <td>0.931005</td>\n",
       "      <td>-0.546012</td>\n",
       "      <td>-0.745097</td>\n",
       "      <td>1.130314</td>\n",
       "      <td>-0.235973</td>\n",
       "      <td>0.812722</td>\n",
       "      <td>0.115093</td>\n",
       "      <td>-0.204064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.314205</td>\n",
       "      <td>-0.808520</td>\n",
       "      <td>0.050343</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>-0.435870</td>\n",
       "      <td>0.124079</td>\n",
       "      <td>0.217940</td>\n",
       "      <td>0.068803</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Time         V1         V2        V3        V4        V5        V6  \\\n",
       "0            0  -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1            0   1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2            1  -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3            1  -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4            2  -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "5            2  -0.425966   0.960523  1.141109 -0.168252  0.420987 -0.029728   \n",
       "6            4   1.229658   0.141004  0.045371  1.202613  0.191881  0.272708   \n",
       "7            7  -0.644269   1.417964  1.074380 -0.492199  0.948934  0.428118   \n",
       "8            7  -0.894286   0.286157 -0.113192 -0.271526  2.669599  3.721818   \n",
       "9            9  -0.338262   1.119593  1.044367 -0.222187  0.499361 -0.246761   \n",
       "10          10   1.449044  -1.176339  0.913860 -1.375667 -1.971383 -0.629152   \n",
       "11          10   0.384978   0.616109 -0.874300 -0.094019  2.924584  3.317027   \n",
       "12          10   1.249999  -1.221637  0.383930 -1.234899 -1.485419 -0.753230   \n",
       "13          11   1.069374   0.287722  0.828613  2.712520 -0.178398  0.337544   \n",
       "14          12  -2.791855  -0.327771  1.641750  1.767473 -0.136588  0.807596   \n",
       "15          12  -0.752417   0.345485  2.057323 -1.468643 -1.158394 -0.077850   \n",
       "16          12   1.103215  -0.040296  1.267332  1.289091 -0.735997  0.288069   \n",
       "17          13  -0.436905   0.918966  0.924591 -0.727219  0.915679 -0.127867   \n",
       "18          14  -5.401258  -5.450148  1.186305  1.736239  3.049106 -1.763406   \n",
       "19          15   1.492936  -1.029346  0.454795 -1.438026 -1.555434 -0.720961   \n",
       "20          16   0.694885  -1.361819  1.029221  0.834159 -1.191209  1.309109   \n",
       "21          17   0.962496   0.328461 -0.171479  2.109204  1.129566  1.696038   \n",
       "22          18   1.166616   0.502120 -0.067300  2.261569  0.428804  0.089474   \n",
       "23          18   0.247491   0.277666  1.185471 -0.092603 -1.314394 -0.150116   \n",
       "24          22  -1.946525  -0.044901 -0.405570 -1.013057  2.941968  2.955053   \n",
       "25          22  -2.074295  -0.121482  1.322021  0.410008  0.295198 -0.959537   \n",
       "26          23   1.173285   0.353498  0.283905  1.133563 -0.172577 -0.916054   \n",
       "27          23   1.322707  -0.174041  0.434555  0.576038 -0.836758 -0.831083   \n",
       "28          23  -0.414289   0.905437  1.727453  1.473471  0.007443 -0.200331   \n",
       "29          23   1.059387  -0.175319  1.266130  1.186110 -0.786002  0.578435   \n",
       "...        ...        ...        ...       ...       ...       ...       ...   \n",
       "284777  172764   2.079137  -0.028723 -1.343392  0.358000 -0.045791 -1.345452   \n",
       "284778  172764  -0.764523   0.588379 -0.907599 -0.418847  0.901528 -0.760802   \n",
       "284779  172766   1.975178  -0.616244 -2.628295 -0.406246  2.327804  3.664740   \n",
       "284780  172766  -1.727503   1.108356  2.219561  1.148583 -0.884199  0.793083   \n",
       "284781  172766  -1.139015  -0.155510  1.894478 -1.138957  1.451777  0.093598   \n",
       "284782  172767  -0.268061   2.540315 -1.400915  4.846661  0.639105  0.186479   \n",
       "284783  172768  -1.796092   1.929178 -2.828417 -1.689844  2.199572  3.123732   \n",
       "284784  172768  -0.669662   0.923769 -1.543167 -1.560729  2.833960  3.240843   \n",
       "284785  172768   0.032887   0.545338 -1.185844 -1.729828  2.932315  3.401529   \n",
       "284786  172768  -2.076175   2.142238 -2.522704 -1.888063  1.982785  3.732950   \n",
       "284787  172769  -1.029719  -1.110670 -0.636179 -0.840816  2.424360 -2.956733   \n",
       "284788  172770   2.007418  -0.280235 -0.208113  0.335261 -0.715798 -0.751373   \n",
       "284789  172770  -0.446951   1.302212 -0.168583  0.981577  0.578957 -0.605641   \n",
       "284790  172771  -0.515513   0.971950 -1.014580 -0.677037  0.912430 -0.316187   \n",
       "284791  172774  -0.863506   0.874701  0.420358 -0.530365  0.356561 -1.046238   \n",
       "284792  172774  -0.724123   1.485216 -1.132218 -0.607190  0.709499 -0.482638   \n",
       "284793  172775   1.971002  -0.699067 -1.697541 -0.617643  1.718797  3.911336   \n",
       "284794  172777  -1.266580  -0.400461  0.956221 -0.723919  1.531993 -1.788600   \n",
       "284795  172778 -12.516732  10.187818 -8.476671 -2.510473 -4.586669 -1.394465   \n",
       "284796  172780   1.884849  -0.143540 -0.999943  1.506772 -0.035300 -0.613638   \n",
       "284797  172782  -0.241923   0.712247  0.399806 -0.463406  0.244531 -1.343668   \n",
       "284798  172782   0.219529   0.881246 -0.635891  0.960928 -0.152971 -1.014307   \n",
       "284799  172783  -1.775135  -0.004235  1.189786  0.331096  1.196063  5.519980   \n",
       "284800  172784   2.039560  -0.175233 -1.196825  0.234580 -0.008713 -0.726571   \n",
       "284801  172785   0.120316   0.931005 -0.546012 -0.745097  1.130314 -0.235973   \n",
       "284802  172786 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
       "284803  172787  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "284804  172788   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "284805  172788  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "284806  172792  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "              V7        V8        V9  ...         V21       V22       V23  \\\n",
       "0       0.239599  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474   \n",
       "1      -0.078803  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288   \n",
       "2       0.791461  0.247676 -1.514654  ...    0.247998  0.771679  0.909412   \n",
       "3       0.237609  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321   \n",
       "4       0.592941 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458   \n",
       "5       0.476201  0.260314 -0.568671  ...   -0.208254 -0.559825 -0.026398   \n",
       "6      -0.005159  0.081213  0.464960  ...   -0.167716 -0.270710 -0.154104   \n",
       "7       1.120631 -3.807864  0.615375  ...    1.943465 -1.015455  0.057504   \n",
       "8       0.370145  0.851084 -0.392048  ...   -0.073425 -0.268092 -0.204233   \n",
       "9       0.651583  0.069539 -0.736727  ...   -0.246914 -0.633753 -0.120794   \n",
       "10     -1.423236  0.048456 -1.720408  ...   -0.009302  0.313894  0.027740   \n",
       "11      0.470455  0.538247 -0.558895  ...    0.049924  0.238422  0.009130   \n",
       "12     -0.689405 -0.227487 -2.094011  ...   -0.231809 -0.483285  0.084668   \n",
       "13     -0.096717  0.115982 -0.221083  ...   -0.036876  0.074412 -0.071407   \n",
       "14     -0.422911 -1.907107  0.755713  ...    1.151663  0.222182  1.020586   \n",
       "15     -0.608581  0.003603 -0.436167  ...    0.499625  1.353650 -0.256573   \n",
       "16     -0.586057  0.189380  0.782333  ...   -0.024612  0.196002  0.013802   \n",
       "17      0.707642  0.087962 -0.665271  ...   -0.194796 -0.672638 -0.156858   \n",
       "18     -1.559738  0.160842  1.233090  ...   -0.503600  0.984460  2.458589   \n",
       "19     -1.080664 -0.053127 -1.978682  ...   -0.177650 -0.175074  0.040002   \n",
       "20     -0.878586  0.445290 -0.446196  ...   -0.295583 -0.571955 -0.050881   \n",
       "21      0.107712  0.521502 -1.191311  ...    0.143997  0.402492 -0.048508   \n",
       "22      0.241147  0.138082 -0.989162  ...    0.018702 -0.061972 -0.103855   \n",
       "23     -0.946365 -1.617935  1.544071  ...    1.650180  0.200454 -0.185353   \n",
       "24     -0.063063  0.855546  0.049967  ...   -0.579526 -0.799229  0.870300   \n",
       "25      0.543985 -0.104627  0.475664  ...   -0.403639 -0.227404  0.742435   \n",
       "26      0.369025 -0.327260 -0.246651  ...    0.067003  0.227812 -0.150487   \n",
       "27     -0.264905 -0.220982 -1.071425  ...   -0.284376 -0.323357 -0.037710   \n",
       "28      0.740228 -0.029247 -0.593392  ...    0.077237  0.457331 -0.038500   \n",
       "29     -0.767084  0.401046  0.699500  ...    0.013676  0.213734  0.014462   \n",
       "...          ...       ...       ...  ...         ...       ...       ...   \n",
       "284777  0.227476 -0.378355  0.665911  ...    0.235758  0.829758 -0.002063   \n",
       "284778  0.758545  0.414698 -0.730854  ...    0.003530 -0.431876  0.141759   \n",
       "284779 -0.533297  0.842937  1.128798  ...    0.086043  0.543613 -0.032129   \n",
       "284780 -0.527298  0.866429  0.853819  ...   -0.094708  0.236818 -0.204280   \n",
       "284781  0.191353  0.092211 -0.062621  ...   -0.191027 -0.631658 -0.147249   \n",
       "284782 -0.045911  0.936448 -2.419986  ...   -0.263889 -0.857904  0.235172   \n",
       "284783 -0.270714  1.657495  0.465804  ...    0.271170  1.145750  0.084783   \n",
       "284784  0.181576  1.282746 -0.893890  ...    0.183856  0.202670 -0.373023   \n",
       "284785  0.337434  0.925377 -0.165663  ...   -0.266113 -0.716336  0.108519   \n",
       "284786 -1.217430 -0.536644  0.272867  ...    2.016666 -1.588269  0.588482   \n",
       "284787  0.283610 -0.332656 -0.247488  ...    0.353722  0.488487  0.293632   \n",
       "284788 -0.458972 -0.140140  0.959971  ...   -0.208260 -0.430347  0.416765   \n",
       "284789  1.253430 -1.042610 -0.417116  ...    0.851800  0.305268 -0.148093   \n",
       "284790  0.396137  0.532364 -0.224606  ...   -0.280302 -0.849919  0.300245   \n",
       "284791  0.757051  0.230473 -0.506856  ...   -0.108846 -0.480820 -0.074513   \n",
       "284792  0.548393  0.343003 -0.226323  ...    0.414621  1.307511 -0.059545   \n",
       "284793 -1.259306  1.056209  1.315006  ...    0.188758  0.694418  0.163002   \n",
       "284794  0.314741  0.004704  0.013857  ...   -0.157831 -0.883365  0.088485   \n",
       "284795 -3.632516  5.498583  4.893089  ...   -0.944759 -1.565026  0.890675   \n",
       "284796  0.190241 -0.249058  0.666458  ...    0.144008  0.634646 -0.042114   \n",
       "284797  0.929369 -0.206210  0.106234  ...   -0.228876 -0.514376  0.279598   \n",
       "284798  0.427126  0.121340 -0.285670  ...    0.099936  0.337120  0.251791   \n",
       "284799 -1.518185  2.080825  1.159498  ...    0.103302  0.654850 -0.348929   \n",
       "284800  0.017050 -0.118228  0.435402  ...   -0.268048 -0.717211  0.297930   \n",
       "284801  0.812722  0.115093 -0.204064  ...   -0.314205 -0.808520  0.050343   \n",
       "284802 -4.918215  7.305334  1.914428  ...    0.213454  0.111864  1.014480   \n",
       "284803  0.024330  0.294869  0.584800  ...    0.214205  0.924384  0.012463   \n",
       "284804 -0.296827  0.708417  0.432454  ...    0.232045  0.578229 -0.037501   \n",
       "284805 -0.686180  0.679145  0.392087  ...    0.265245  0.800049 -0.163298   \n",
       "284806  1.577006 -0.414650  0.486180  ...    0.261057  0.643078  0.376777   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "0       0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1      -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2      -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3      -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4       0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "5      -0.371427 -0.232794  0.105915  0.253844  0.081080    3.67      0  \n",
       "6      -0.780055  0.750137 -0.257237  0.034507  0.005168    4.99      0  \n",
       "7      -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   40.80      0  \n",
       "8       1.011592  0.373205 -0.384157  0.011747  0.142404   93.20      0  \n",
       "9      -0.385050 -0.069733  0.094199  0.246219  0.083076    3.68      0  \n",
       "10      0.500512  0.251367 -0.129478  0.042850  0.016253    7.80      0  \n",
       "11      0.996710 -0.767315 -0.492208  0.042472 -0.054337    9.99      0  \n",
       "12      0.392831  0.161135 -0.354990  0.026416  0.042422  121.50      0  \n",
       "13      0.104744  0.548265  0.104094  0.021491  0.021293   27.50      0  \n",
       "14      0.028317 -0.232746 -0.235557 -0.164778 -0.030154   58.80      0  \n",
       "15     -0.065084 -0.039124 -0.087086 -0.180998  0.129394   15.99      0  \n",
       "16      0.103758  0.364298 -0.382261  0.092809  0.037051   12.99      0  \n",
       "17     -0.888386 -0.342413 -0.049027  0.079692  0.131024    0.89      0  \n",
       "18      0.042119 -0.481631 -0.621272  0.392053  0.949594   46.80      0  \n",
       "19      0.295814  0.332931 -0.220385  0.022298  0.007602    5.00      0  \n",
       "20     -0.304215  0.072001 -0.422234  0.086553  0.063499  231.71      0  \n",
       "21     -1.371866  0.390814  0.199964  0.016371 -0.014605   34.09      0  \n",
       "22     -0.370415  0.603200  0.108556 -0.040521 -0.011418    2.28      0  \n",
       "23      0.423073  0.820591 -0.227632  0.336634  0.250475   22.75      0  \n",
       "24      0.983421  0.321201  0.149650  0.707519  0.014600    0.89      0  \n",
       "25      0.398535  0.249212  0.274404  0.359969  0.243232   26.43      0  \n",
       "26      0.435045  0.724825 -0.337082  0.016368  0.030041   41.88      0  \n",
       "27      0.347151  0.559639 -0.280158  0.042335  0.028822   16.00      0  \n",
       "28      0.642522 -0.183891 -0.277464  0.182687  0.152665   33.00      0  \n",
       "29      0.002951  0.294638 -0.395070  0.081461  0.024220   12.99      0  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "284777  0.001344  0.262183 -0.105327 -0.022363 -0.060283    1.00      0  \n",
       "284778  0.587119 -0.200998  0.267337 -0.152951 -0.065285   80.00      0  \n",
       "284779  0.768379  0.477688 -0.031833  0.014151 -0.066542   25.00      0  \n",
       "284780  1.158185  0.627801 -0.399981  0.510818  0.233265   30.00      0  \n",
       "284781  0.212931  0.354257 -0.241068 -0.161717 -0.149188   13.00      0  \n",
       "284782 -0.681794 -0.668894  0.044657 -0.066751 -0.072447   12.82      0  \n",
       "284783  0.721269 -0.529906 -0.240117  0.129126 -0.080620   11.46      0  \n",
       "284784  0.651122  1.073823  0.844590 -0.286676 -0.187719   40.00      0  \n",
       "284785  0.688519 -0.460220  0.161939  0.265368  0.090245    1.79      0  \n",
       "284786  0.632444 -0.201064  0.199251  0.438657  0.172923    8.95      0  \n",
       "284787  0.107812 -0.935586  1.138216  0.025271  0.255347    9.99      0  \n",
       "284788  0.064819 -0.608337  0.268436 -0.028069 -0.041367    3.99      0  \n",
       "284789 -0.038712  0.010209 -0.362666  0.503092  0.229921   60.50      0  \n",
       "284790  0.000607 -0.376379  0.128660 -0.015205 -0.021486    9.81      0  \n",
       "284791 -0.003988 -0.113149  0.280378 -0.077310  0.023079   20.32      0  \n",
       "284792  0.242669 -0.665424 -0.269869 -0.170579 -0.030692    3.99      0  \n",
       "284793  0.726365 -0.058282 -0.191813  0.061858 -0.043716    4.99      0  \n",
       "284794 -0.076790 -0.095833  0.132720 -0.028468  0.126494    0.89      0  \n",
       "284795 -1.253276  1.786717  0.320763  2.090712  1.232864    9.87      0  \n",
       "284796 -0.053206  0.316403 -0.461441  0.018265 -0.041068   60.00      0  \n",
       "284797  0.371441 -0.559238  0.113144  0.131507  0.081265    5.49      0  \n",
       "284798  0.057688 -1.508368  0.144023  0.181205  0.215243   24.05      0  \n",
       "284799  0.745323  0.704545 -0.127579  0.454379  0.130308   79.99      0  \n",
       "284800 -0.359769 -0.315610  0.201114 -0.080826 -0.075071    2.68      0  \n",
       "284801  0.102800 -0.435870  0.124079  0.217940  0.068803    2.69      0  \n",
       "284802 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77      0  \n",
       "284803 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79      0  \n",
       "284804  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88      0  \n",
       "284805  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00      0  \n",
       "284806  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## loading the data\n",
    "\n",
    "data=pd.read_csv(\"creditcard data set.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### checking the shape of the data\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.165980e-15</td>\n",
       "      <td>3.400941e-16</td>\n",
       "      <td>-1.373150e-15</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.487313e-15</td>\n",
       "      <td>-5.548484e-16</td>\n",
       "      <td>1.056807e-16</td>\n",
       "      <td>-2.406206e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.662549e-16</td>\n",
       "      <td>-3.560610e-16</td>\n",
       "      <td>2.608586e-16</td>\n",
       "      <td>4.474413e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.686512e-15</td>\n",
       "      <td>-3.684602e-16</td>\n",
       "      <td>-1.193648e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.165980e-15  3.400941e-16 -1.373150e-15  2.074095e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.487313e-15 -5.548484e-16  1.056807e-16 -2.406206e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.662549e-16 -3.560610e-16  2.608586e-16  4.474413e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.686512e-15 -3.684602e-16 -1.193648e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking the summary of our data\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking  the names of the columns we have in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking  the names of the columns we have in our data\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().values.any()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking whether the data is balanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>284315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Amount\n",
       "Class        \n",
       "0      284315\n",
       "1         492"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data=data[['Amount','Class']].groupby('Class').count()\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Class',data=data,label='0=Legitimate',color='purple')\n",
    "sns.countplot(x='Class',data=data,label='1=fraudulent',color='purple')\n",
    "plt.title('Legitimate and fraudulent transactions')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering the relevant features using a correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize = (12,12))\n",
    "plt.title('Features correlation plot using Pearson')\n",
    "corr = data.corr()## generating the correlation matrix\n",
    "##sns.heatmap(corr)-generating the correlation heatmap\n",
    "sns.heatmap(corr,xticklabels=corr.columns,yticklabels=corr.columns,linewidths=.1,cmap=\"seismic\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the correlation matrix we notice no correlation between the features V1-V28.\n",
    "\n",
    "The variable Amount has a negative correlation with variables V2 and V5 and a positive correlation with the variables V7 and V20.\n",
    "\n",
    "The variable time has a negative correlation with the vaarable V3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standardizing the amount column \n",
    "data['normAmount'] = StandardScaler().fit_transform(np.array(data['Amount']).reshape(-1, 1)) \n",
    "  \n",
    "# drop Time and Amount columns as they are not relevant for prediction purpose  \n",
    "data = data.drop(['Time','Amount'], axis = 1) \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning x and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##assigning x and y\n",
    "##droping the predicted column\n",
    "\n",
    "y=data.Class\n",
    "x = data.drop('Class',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Class', 'normAmount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions in the X_train :  (199364, 29)\n",
      "Number of transactions in the y_train :  (199364,)\n",
      "Number of transactions in the X_test :  (85443, 29)\n",
      "Number of transactions in the y_test :  (85443,)\n"
     ]
    }
   ],
   "source": [
    "## Splitting the data \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42) \n",
    "  \n",
    "## The shape of our train and test data \n",
    "print(\"Number of transactions in the X_train : \", x_train.shape) \n",
    "print(\"Number of transactions in the y_train : \", y_train.shape) \n",
    "print(\"Number of transactions in the X_test : \", x_test.shape) \n",
    "print(\"Number of transactions in the y_test : \", y_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'normAmount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking the number of columns after dropping our predicted column\n",
    "\n",
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Different classifiers using an imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**\n",
    "\n",
    "**Advantages**\n",
    "\n",
    "- Does not suffer from overfiting because it takes the average of all the predictions, which cancels out the biases.\n",
    "\n",
    "**Disadvantages**\n",
    "\n",
    "- It is time-consuming because it has multiple decision trees and when making any prediction all the trees in the forest has to make prediction for the same input and then a vote is made and the prediction with the highest votes is taken as the final prediction.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training the model\n",
    "random_mod = RandomForestClassifier(n_estimators=400).fit(x_train, y_train)\n",
    "\n",
    "## Predicting on the training set\n",
    "ry_pred = random_mod.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.9996371850239341\n"
     ]
    }
   ],
   "source": [
    "## After training, we check the accuracy using actual and predicted value\n",
    "\n",
    "print(\"The accuracy is:\",metrics.accuracy_score(y_test, ry_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.94      0.82      0.88       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.97      0.91      0.94     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## The precision,recall and f1-score\n",
    "\n",
    "print(classification_report(y_test, ry_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85296</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  85296   11\n",
       "1     28  108"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The confusion matrix\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, ry_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive-bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive bayes**\n",
    "\n",
    "**Advantages**\n",
    "- Naive Bayes has very low computation cost.\n",
    "- Fast when making predictions.\n",
    "\n",
    "**Disadvantages**\n",
    "- The assumption of independent features is almost impossible in real world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Gaussian Classifier\n",
    "gaus_naive_mod = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "gaus_naive_mod.fit(x_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "ny_pred = gaus_naive_mod.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.9780906569291808\n"
     ]
    }
   ],
   "source": [
    "## After training, we check the accuracy using actual and predicted value\n",
    "\n",
    "print(\"The accuracy is:\",metrics.accuracy_score(y_test, ny_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     85307\n",
      "           1       0.06      0.85      0.11       136\n",
      "\n",
      "    accuracy                           0.98     85443\n",
      "   macro avg       0.53      0.91      0.55     85443\n",
      "weighted avg       1.00      0.98      0.99     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## The precision,recall and f1-score\n",
    "\n",
    "print(classification_report(y_test, ny_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-973fe6ee8396>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## The confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mny_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "## The confusion matrix\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, ny_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.88      0.62      0.73       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.94      0.81      0.86     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# logistic regression object \n",
    "lr = LogisticRegression() \n",
    "  \n",
    "# train the model on train set \n",
    "lr.fit(x_train, y_train.ravel()) \n",
    "  \n",
    "predictions = lr.predict(x_test) \n",
    "  \n",
    "# print classification report \n",
    "print(classification_report(y_test, predictions)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85295</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1\n",
       "0  85295  12\n",
       "1     51  85"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': 356\n",
      "Before OverSampling, counts of label '0': 199008 \n",
      "\n",
      "After OverSampling, counts of label '1': 199008\n",
      "After OverSampling, counts of label '0': 199008\n"
     ]
    }
   ],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "x_train_res, y_train_res = sm.fit_sample(x_train, y_train.ravel())\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398016, 29)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398016,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(x_train_res, y_train_res.ravel())\n",
    "knn_pred=classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8970588235294118"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, knn_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44525547445255476"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, knn_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5951219512195122"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, knn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9980571843217115\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.45      0.90      0.60       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.72      0.95      0.80     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85155</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  85155  152\n",
       "1     14  122"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The confusion matrix\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, knn_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = RandomForestClassifier(n_estimators=400).fit(x_train_res, y_train_res.ravel())\n",
    "\n",
    "smote_pred = smote.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9995435553526912\n"
     ]
    }
   ],
   "source": [
    "## After training, we check the accuracy using actual and predicted value\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, smote_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.85      0.87      0.86       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.92      0.93      0.93     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, smote_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85286</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  85286   21\n",
       "1     18  118"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The confusion matrix\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, smote_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame({'feature':x_train.columns,'importance':np.round(random_forest.feature_importances_,3)})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     85307\n",
      "           1       0.05      0.93      0.10       136\n",
      "\n",
      "    accuracy                           0.97     85443\n",
      "   macro avg       0.53      0.95      0.54     85443\n",
      "weighted avg       1.00      0.97      0.98     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr1 = LogisticRegression() \n",
    "lr1.fit(x_train_res, y_train_res.ravel()) \n",
    "predictions = lr1.predict(x_test) \n",
    "  \n",
    "# print classification report \n",
    "print(classification_report(y_test, predictions)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82993</td>\n",
       "      <td>2314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1\n",
       "0  82993  2314\n",
       "1     10   126"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Gaussian Classifier\n",
    "gaus_naive_mod = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "gaus_naive_mod.fit(x_train_res, y_train_res.ravel())\n",
    "\n",
    "#Predict the response for test dataset\n",
    "nby_pred = gaus_naive_mod.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     85307\n",
      "           1       0.06      0.88      0.11       136\n",
      "\n",
      "    accuracy                           0.98     85443\n",
      "   macro avg       0.53      0.93      0.55     85443\n",
      "weighted avg       1.00      0.98      0.99     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## The precision,recall and f1-score\n",
    "\n",
    "print(classification_report(y_test, nby_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83295</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1\n",
       "0  83295  2012\n",
       "1     16   120"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, nby_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under sampling using Near miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Undersampling, counts of label '1': 356\n",
      "Before Undersampling, counts of label '0': 199008 \n",
      "\n",
      "After Undersampling, the shape of train_X: (656, 29)\n",
      "After Undersampling, the shape of train_y: (656,) \n",
      "\n",
      "After Undersampling, counts of label '1': 356\n",
      "After Undersampling, counts of label '0': 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carolyne/.local/lib/python3.7/site-packages/imblearn/under_sampling/_prototype_selection/_nearmiss.py:175: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  \"The number of the samples to be selected is larger\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Before Undersampling, counts of label '1': {}\".format(sum(y_train == 1))) \n",
    "print(\"Before Undersampling, counts of label '0': {} \\n\".format(sum(y_train == 0))) \n",
    "  \n",
    "# apply near miss \n",
    "from imblearn.under_sampling import NearMiss \n",
    "nr = NearMiss(version=3) \n",
    "  \n",
    "x_train_miss, y_train_miss = nr.fit_sample(x_train, y_train.ravel()) \n",
    "  \n",
    "print('After Undersampling, the shape of train_X: {}'.format(x_train_miss.shape)) \n",
    "print('After Undersampling, the shape of train_y: {} \\n'.format(y_train_miss.shape)) \n",
    "  \n",
    "print(\"After Undersampling, counts of label '1': {}\".format(sum(y_train_miss == 1))) \n",
    "print(\"After Undersampling, counts of label '0': {}\".format(sum(y_train_miss == 0))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning - RF -Nearmiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "random_search = {'criterion': ['entropy', 'gini'],\n",
    "               'max_depth': list(np.linspace(10, 1200, 10, dtype = int)) + [None],\n",
    "               'max_features': ['auto', 'sqrt','log2'],\n",
    "               'min_samples_leaf': [4, 6, 8, 12],\n",
    "               'min_samples_split': [5, 7, 10, 14],\n",
    "               'n_estimators': list(np.linspace(151, 1200, 10, dtype = int))}\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "model1 = RandomizedSearchCV(estimator = clf, param_distributions = random_search, n_iter = 80, \n",
    "                               cv = 5, verbose= 5, random_state= 101, n_jobs = -1)\n",
    "model1.fit(x_train_miss, y_train_miss)\n",
    "print(model1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest- Near miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearmiss = RandomForestClassifier(n_estimators=100).fit(x_train_miss, y_train_miss.ravel())\n",
    "\n",
    "nearmiss_pred = nearmiss.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     85307\n",
      "           1       0.17      0.86      0.29       136\n",
      "\n",
      "    accuracy                           0.99     85443\n",
      "   macro avg       0.59      0.93      0.64     85443\n",
      "weighted avg       1.00      0.99      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, nearmiss_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84808</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  84808  499\n",
       "1     19  117"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, nearmiss_pred ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Gaussian Classifier\n",
    "gaus_naive_mod = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "gaus_naive_mod.fit(x_train_miss, y_train_miss.ravel())\n",
    "\n",
    "#Predict the response for test dataset\n",
    "Nby_pred = gaus_naive_mod.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     85307\n",
      "           1       0.12      0.57      0.20       136\n",
      "\n",
      "    accuracy                           0.99     85443\n",
      "   macro avg       0.56      0.78      0.60     85443\n",
      "weighted avg       1.00      0.99      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, Nby_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84753</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  84753  554\n",
       "1     59   77"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, Nby_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "# specify \"parameter distributions\" rather than a \"parameter grid\"\n",
    "\n",
    "# since both parameters are discrete, so param_dist is the same as param_grid\n",
    "param_dist = dict(n_neighbors=k_range, weights=weight_options)\n",
    "\n",
    "# if parameters are continuous (like regularization)\n",
    "\n",
    "# n_iter controls the number of searches\n",
    "\n",
    "# instantiate model\n",
    "# 2 new params\n",
    "# n_iter --> controls number of random combinations it will try\n",
    "# random_state for reproducibility \n",
    "knn=KNeighborsClassifier()\n",
    "rand1 = RandomizedSearchCV(knn, param_dist, cv=5, scoring='accuracy', n_iter=80, random_state=5)\n",
    "\n",
    "# fit\n",
    "rand1.fit(x_train_miss, y_train_miss)\n",
    "print(rand1.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN- Nearmiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(x_train_miss, y_train_miss.ravel())\n",
    "Knn_Pred=classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     85307\n",
      "           1       0.20      0.80      0.32       136\n",
      "\n",
      "    accuracy                           0.99     85443\n",
      "   macro avg       0.60      0.90      0.66     85443\n",
      "weighted avg       1.00      0.99      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## The precision,recall and f1-score\n",
    "\n",
    "print(classification_report(y_test, Knn_Pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84872</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  84872  435\n",
       "1     27  109"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, Knn_Pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(x_train_miss, y_train_miss)\n",
    "SVc_Pred=classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     85307\n",
      "           1       0.20      0.80      0.32       136\n",
      "\n",
      "    accuracy                           0.99     85443\n",
      "   macro avg       0.60      0.90      0.66     85443\n",
      "weighted avg       1.00      0.99      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report \n",
    "print(classification_report(y_test, SVc_Pred )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84872</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  84872  435\n",
       "1     27  109"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, SVc_Pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling(SMOTE) followed by under sampling(Tomek links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTETomek(random_state=2)\n",
    "x_train_smt, y_train_smt = smt.fit_sample(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape is: (398016, 29)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape is:\",x_train_smt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398016,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_smt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning -KNN- Smote+tomeklink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "# specify \"parameter distributions\" rather than a \"parameter grid\"\n",
    "\n",
    "# since both parameters are discrete, so param_dist is the same as param_grid\n",
    "param_dist = dict(n_neighbors=k_range, weights=weight_options)\n",
    "\n",
    "# if parameters are continuous (like regularization)\n",
    "\n",
    "# n_iter controls the number of searches\n",
    "\n",
    "# instantiate model\n",
    "# 2 new params\n",
    "# n_iter --> controls number of random combinations it will try\n",
    "# random_state for reproducibility \n",
    "Knn=KNeighborsClassifier()\n",
    "rand2 = RandomizedSearchCV(Knn, param_dist, cv=5, scoring='accuracy', n_iter=80, random_state=5)\n",
    "\n",
    "# fit\n",
    "rand2.fit(x_train_smt, y_train_smt)\n",
    "\n",
    "print(rand2.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN - smote+tomek link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(x_train_smt, y_train_smt.ravel())\n",
    "Knn_pred=classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.45      0.90      0.60       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.72      0.95      0.80     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## The precision,recall and f1-score\n",
    "\n",
    "print(classification_report(y_test, Knn_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85155</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  85155  152\n",
       "1     14  122"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, Knn_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning -Rf- Smote + Tomeklink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = {'criterion': ['entropy', 'gini'],\n",
    "               'max_depth': list(np.linspace(10, 1200, 10, dtype = int)) + [None],\n",
    "               'max_features': ['auto', 'sqrt','log2'],\n",
    "               'min_samples_leaf': [4, 6, 8, 12],\n",
    "               'min_samples_split': [5, 7, 10, 14],\n",
    "               'n_estimators': list(np.linspace(151, 1200, 10, dtype = int))}\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "model2 = RandomizedSearchCV(estimator = clf, param_distributions = random_search, n_iter = 80, \n",
    "                               cv = 5, verbose= 5, random_state= 101, n_jobs = -1)\n",
    "model2.fit(x_train_smt, y_train_smt)\n",
    "print(model2.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tomek link - Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "smotek = RandomForestClassifier(n_jobs = -1,\n",
    "                                random_state = 42).fit(x_train_smt, y_train_smt.ravel())\n",
    "\n",
    "smotek_pred = smotek.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.86      0.88      0.87       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.93      0.94      0.93     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## The precision,recall and f1-score\n",
    "\n",
    "print(classification_report(y_test, smotek_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85287</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  85287   20\n",
       "1     17  119"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, smotek_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Gaussian Classifier\n",
    "gaus_naive_mod = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "gaus_naive_mod.fit(x_train_smt, y_train_smt.ravel())\n",
    "\n",
    "#Predict the response for test dataset\n",
    "Nnby_pred = gaus_naive_mod.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     85307\n",
      "           1       0.06      0.88      0.11       136\n",
      "\n",
      "    accuracy                           0.98     85443\n",
      "   macro avg       0.53      0.93      0.55     85443\n",
      "weighted avg       1.00      0.98      0.99     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## The precision,recall and f1-score\n",
    "\n",
    "print(classification_report(y_test, Nnby_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83295</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1\n",
       "0  83295  2012\n",
       "1     16   120"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, Nnby_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     85307\n",
      "           1       0.05      0.93      0.10       136\n",
      "\n",
      "    accuracy                           0.97     85443\n",
      "   macro avg       0.53      0.95      0.54     85443\n",
      "weighted avg       1.00      0.97      0.98     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression() \n",
    "lr.fit(x_train_smt, y_train_smt.ravel()) \n",
    "prediction = lr.predict(x_test) \n",
    "  \n",
    "# print classification report \n",
    "print(classification_report(y_test, prediction)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82993</td>\n",
       "      <td>2314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1\n",
       "0  82993  2314\n",
       "1     10   126"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(x_train_smt, y_train_smt)\n",
    "SVc_pred=classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.73     85307\n",
      "           1       0.00      0.92      0.01       136\n",
      "\n",
      "    accuracy                           0.57     85443\n",
      "   macro avg       0.50      0.74      0.37     85443\n",
      "weighted avg       1.00      0.57      0.72     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report \n",
    "print(classification_report(y_test, SVc_pred )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48602</td>\n",
       "      <td>36705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1\n",
       "0  48602  36705\n",
       "1     11    125"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, SVc_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edited Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "renn = EditedNearestNeighbours()\n",
    "x_train_enn, y_train_enn= renn.fit_resample(x_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "editednn = RandomForestClassifier(n_estimators=10).fit(x_train_enn, y_train_enn.ravel())\n",
    "\n",
    "editednn_pred = editednn.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.82      0.82      0.82       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.91      0.91      0.91     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report \n",
    "print(classification_report(y_test, editednn_pred )) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85283</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  85283   24\n",
       "1     24  112"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, editednn_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Gaussian Classifier\n",
    "gaus_naive_mod = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "gaus_naive_mod.fit(x_train_enn, y_train_enn.ravel())\n",
    "\n",
    "#Predict the response for test dataset\n",
    "NBy_pred = gaus_naive_mod.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     85307\n",
      "           1       0.06      0.85      0.11       136\n",
      "\n",
      "    accuracy                           0.98     85443\n",
      "   macro avg       0.53      0.91      0.55     85443\n",
      "weighted avg       1.00      0.98      0.99     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report \n",
    "print(classification_report(y_test, NBy_pred )) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83446</td>\n",
       "      <td>1861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1\n",
       "0  83446  1861\n",
       "1     21   115"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, NBy_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(x_train_enn, y_train_enn.ravel())\n",
    "KNn_pred=classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.82      0.81      0.81       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.91      0.90      0.91     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report \n",
    "print(classification_report(y_test, KNn_pred)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85283</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  85283   24\n",
       "1     26  110"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, KNn_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(x_train_enn, y_train_enn)\n",
    "svc_pred=classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.86      0.79      0.82       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.93      0.89      0.91     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report \n",
    "print(classification_report(y_test, svc_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85290</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  85290   17\n",
       "1     29  107"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, svc_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling(ENN rule) followed by undersampling(CNN rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edited Nearest Neighbor and Condensed Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ncr=NeighbourhoodCleaningRule()\n",
    "x_train_ncr, y_train_ncr= Ncr.fit_resample(x_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning - RF -ENN+CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = {'criterion': ['entropy', 'gini'],\n",
    "               'max_depth': list(np.linspace(10, 1200, 10, dtype = int)) + [None],\n",
    "               'max_features': ['auto', 'sqrt','log2'],\n",
    "               'min_samples_leaf': [4, 6, 8, 12],\n",
    "               'min_samples_split': [5, 7, 10, 14],\n",
    "               'n_estimators': list(np.linspace(151, 1200, 10, dtype = int))}\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "model3 = RandomizedSearchCV(estimator = clf, param_distributions = random_search, n_iter = 80, \n",
    "                               cv = 5, verbose= 5, random_state= 101, n_jobs = -1)\n",
    "model3.fit(x_train_ncr, y_train_ncr)\n",
    "\n",
    "print(model3.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest - ENN+CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecnn = RandomForestClassifier(n_estimators=400).fit(x_train_ncr, y_train_ncr.ravel())\n",
    "\n",
    "ecnn_pred = ecnn.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.85      0.85      0.85       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.92      0.92      0.92     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report \n",
    "print(classification_report(y_test, ecnn_pred)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85286</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  85286   21\n",
       "1     21  115"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, ecnn_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Gaussian Classifier\n",
    "gaus_naive_mod = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "gaus_naive_mod.fit(x_train_ncr, y_train_ncr.ravel())\n",
    "\n",
    "#Predict the response for test dataset\n",
    "NBY_pred = gaus_naive_mod.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     85307\n",
      "           1       0.06      0.85      0.11       136\n",
      "\n",
      "    accuracy                           0.98     85443\n",
      "   macro avg       0.53      0.91      0.55     85443\n",
      "weighted avg       1.00      0.98      0.99     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report \n",
    "print(classification_report(y_test, NBY_pred)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83442</td>\n",
       "      <td>1865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1\n",
       "0  83442  1865\n",
       "1     21   115"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, NBY_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning - KNN -EnN+cNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "# specify \"parameter distributions\" rather than a \"parameter grid\"\n",
    "\n",
    "# since both parameters are discrete, so param_dist is the same as param_grid\n",
    "param_dist = dict(n_neighbors=k_range, weights=weight_options)\n",
    "\n",
    "# if parameters are continuous (like regularization)\n",
    "\n",
    "# n_iter controls the number of searches\n",
    "\n",
    "# instantiate model\n",
    "# 2 new params\n",
    "# n_iter --> controls number of random combinations it will try\n",
    "# random_state for reproducibility \n",
    "KNn=KNeighborsClassifier()\n",
    "rand3 = RandomizedSearchCV(KNn, param_dist, cv=5, scoring='accuracy', n_iter=80, random_state=5)\n",
    "\n",
    "# fit\n",
    "rand3.fit(x_train_ncr, y_train_ncr)\n",
    "\n",
    "\n",
    "print(rand3.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN- ENN+CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=11,p=2,metric='euclidean')\n",
    "classifier.fit(x_train_ncr, y_train_ncr.ravel())\n",
    "KNN_pred=classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.83      0.82      0.83       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.92      0.91      0.91     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report \n",
    "print(classification_report(y_test, KNN_pred)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85285</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  85285   22\n",
       "1     25  111"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, KNN_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(x_train_ncr, y_train_ncr)\n",
    "Svc_pred=classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.86      0.79      0.82       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.93      0.89      0.91     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, Svc_pred)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85290</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  85290   17\n",
       "1     29  107"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, Svc_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling(Tomek links) followed by an undersampling(CNN rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "OSS=OneSidedSelection()\n",
    "x_train_oss, y_train_oss= OSS.fit_resample(x_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctomel = RandomForestClassifier(n_estimators=10).fit(x_train_oss, y_train_oss.ravel())\n",
    "\n",
    "ctomel_pred = ctomel.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.94      0.78      0.85       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.97      0.89      0.93     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report \n",
    "print(classification_report(y_test, ctomel_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85300</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  85300    7\n",
       "1     30  106"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, ctomel_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Gaussian Classifier\n",
    "gaus_naive_mod = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "gaus_naive_mod.fit(x_train_oss, y_train_oss.ravel())\n",
    "\n",
    "#Predict the response for test dataset\n",
    "NBY_Pred = gaus_naive_mod.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     85307\n",
      "           1       0.06      0.85      0.11       136\n",
      "\n",
      "    accuracy                           0.98     85443\n",
      "   macro avg       0.53      0.91      0.55     85443\n",
      "weighted avg       1.00      0.98      0.99     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report \n",
    "print(classification_report(y_test, NBY_Pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83468</td>\n",
       "      <td>1839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1\n",
       "0  83468  1839\n",
       "1     21   115"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, NBY_Pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(x_train_oss, y_train_oss.ravel())\n",
    "KNN_Pred=classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.86      0.79      0.82       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.93      0.89      0.91     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report \n",
    "print(classification_report(y_test, KNN_Pred)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85290</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  85290   17\n",
       "1     29  107"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, KNN_Pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receiver Operating Characteristic (ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
